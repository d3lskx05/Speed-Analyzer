import os
import shutil
import tempfile
import time
import psutil
import pandas as pd
import matplotlib.pyplot as plt
import streamlit as st
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from datetime import datetime
import gdown
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
from reportlab.lib import colors
from reportlab.lib.pagesizes import letter
from reportlab.lib.styles import getSampleStyleSheet

st.set_page_config(page_title="Model Performance Analyzer", layout="wide")

# -------------------------------
# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏
# -------------------------------
if "history" not in st.session_state:
    st.session_state["history"] = []

# -------------------------------
# –§—É–Ω–∫—Ü–∏–∏
# -------------------------------
def download_model_from_gdrive(file_id: str) -> str:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å Google Drive –ø–æ ID"""
    model_path = f"/tmp/{file_id}"
    if not os.path.exists(model_path):
        os.makedirs(model_path, exist_ok=True)
        url = f"https://drive.google.com/uc?id={file_id}"
        output = os.path.join(model_path, "model.zip")
        gdown.download(url, output, quiet=False)
        shutil.unpack_archive(output, model_path)
        os.remove(output)
    return model_path

def load_model(source: str, model_id: str) -> SentenceTransformer:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: HuggingFace –∏–ª–∏ GDrive"""
    if source == "HuggingFace":
        return SentenceTransformer(model_id)
    elif source == "Google Drive":
        return SentenceTransformer(download_model_from_gdrive(model_id))
    else:
        raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –º–æ–¥–µ–ª–∏")

def measure_performance(model, sentences):
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏, –ø–∞–º—è—Ç–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏"""
    start_time = time.time()
    process = psutil.Process(os.getpid())
    start_mem = process.memory_info().rss / 1024 / 1024  # MB

    embeddings = model.encode(sentences, convert_to_tensor=False)
    end_time = time.time()
    end_mem = process.memory_info().rss / 1024 / 1024

    duration = end_time - start_time
    mem_used = end_mem - start_mem
    similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]

    return {
        "–í—Ä–µ–º—è (—Å–µ–∫)": round(duration, 4),
        "–ü–∞–º—è—Ç—å (MB)": round(mem_used, 4),
        "–°—Ö–æ–¥—Å—Ç–≤–æ": round(similarity, 4)
    }

def plot_metric(history_df, metric_name):
    """–ì—Ä–∞—Ñ–∏–∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏"""
    fig, ax = plt.subplots()
    ax.plot(history_df["–î–∞—Ç–∞"], history_df[metric_name], marker="o")
    ax.set_title(f"{metric_name} –ø–æ —Ç–µ—Å—Ç–∞–º")
    ax.set_xlabel("–î–∞—Ç–∞")
    ax.set_ylabel(metric_name)
    st.pyplot(fig)

def clear_tmp_dir(model_path):
    """–£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–ø–∫–∏ –º–æ–¥–µ–ª–∏ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ"""
    if os.path.exists(model_path):
        size_before = sum(os.path.getsize(os.path.join(dp, f)) for dp, dn, filenames in os.walk(model_path) for f in filenames)
        shutil.rmtree(model_path)
        st.write(f"üóë –ü–∞–ø–∫–∞ {model_path} —É–¥–∞–ª–µ–Ω–∞, –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ {size_before/1024/1024:.2f} MB")

def save_pdf_report(result, recommendations, img_paths):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è PDF –æ—Ç—á–µ—Ç–∞"""
    file_path = "/tmp/report.pdf"
    doc = SimpleDocTemplate(file_path, pagesize=letter)
    styles = getSampleStyleSheet()
    story = [Paragraph("–û—Ç—á–µ—Ç –ø–æ —Ç–µ—Å—Ç—É –º–æ–¥–µ–ª–∏", styles["Title"]), Spacer(1, 12)]

    # –¢–∞–±–ª–∏—Ü–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    data = [["–ú–µ—Ç—Ä–∏–∫–∞", "–ó–Ω–∞—á–µ–Ω–∏–µ"]] + [[k, v] for k, v in result.items()]
    table = Table(data)
    table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('GRID', (0, 0), (-1, -1), 1, colors.black)
    ]))
    story.append(table)
    story.append(Spacer(1, 12))

    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    story.append(Paragraph("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:", styles["Heading2"]))
    for rec in recommendations:
        story.append(Paragraph(f"- {rec}", styles["Normal"]))

    doc.build(story)
    return file_path

# -------------------------------
# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å
# -------------------------------
st.title("üîç –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏")

# –û—á–∏—Å—Ç–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø—Ä–∏ –Ω–æ–≤–æ–º —Ç–µ—Å—Ç–µ
st.subheader("1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–µ—Å—Ç–∞")
source = st.selectbox("–ò—Å—Ç–æ—á–Ω–∏–∫ –º–æ–¥–µ–ª–∏", ["HuggingFace", "Google Drive"])
model_id = st.text_input("ID –º–æ–¥–µ–ª–∏ –∏–ª–∏ GDrive File ID")
sentences = st.text_area("–í–≤–µ–¥–∏—Ç–µ 2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Enter", "–ü—Ä–∏–≤–µ—Ç –º–∏—Ä\n–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ –º–∏—Ä")

if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç"):
    st.session_state["analytics"] = {}  # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏

    with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏..."):
        model = load_model(source, model_id)

    st.success("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")

    with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ..."):
        lines = sentences.split("\n")
        result = measure_performance(model, lines[:2])

    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
    st.session_state["history"].append({
        "–î–∞—Ç–∞": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "–ú–æ–¥–µ–ª—å": model_id,
        **result
    })

    # –ê–Ω–∞–ª–∏—Ç–∏–∫–∞
    st.markdown("### üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞")
    st.write(result)

    # –ì—Ä–∞—Ñ–∏–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å –∏—Å—Ç–æ—Ä–∏—è)
    if len(st.session_state["history"]) > 1:
        history_df = pd.DataFrame(st.session_state["history"])
        for metric in ["–í—Ä–µ–º—è (—Å–µ–∫)", "–ü–∞–º—è—Ç—å (MB)", "–°—Ö–æ–¥—Å—Ç–≤–æ"]:
            plot_metric(history_df, metric)

    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    recommendations = []
    if result["–í—Ä–µ–º—è (—Å–µ–∫)"] > 2:
        recommendations.append("–ú–æ–¥–µ–ª—å —Å–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω–∞—è –¥–ª—è Streamlit Free.")
    if result["–ü–∞–º—è—Ç—å (MB)"] > 200:
        recommendations.append("–í—ã—Å–æ–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ ‚Äî –ø–æ–ø—Ä–æ–±—É–π—Ç–µ quantization.")
    if not recommendations:
        recommendations.append("–ú–æ–¥–µ–ª—å –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.")

    st.markdown("### ‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
    for rec in recommendations:
        st.write(f"- {rec}")

    # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∞—Ç—å PDF
    pdf_path = save_pdf_report(result, recommendations, [])
    with open(pdf_path, "rb") as f:
        st.download_button("üì• –°–∫–∞—á–∞—Ç—å –æ—Ç—á–µ—Ç (PDF)", f, file_name="report.pdf")

    # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
    if source == "Google Drive":
        clear_tmp_dir(f"/tmp/{model_id}")

# -------------------------------
# –ò—Å—Ç–æ—Ä–∏—è —Ç–µ—Å—Ç–æ–≤
# -------------------------------
st.markdown("### üóÇ –ò—Å—Ç–æ—Ä–∏—è —Ç–µ—Å—Ç–æ–≤")
if st.session_state["history"]:
    df_history = pd.DataFrame(st.session_state["history"])
    st.dataframe(df_history)
